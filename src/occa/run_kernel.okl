//  ISSUES:
//    - Source_Arrays struct may need to be split up into three arrays
//    - Alternatives must be found for curand and curandState
//    - Does OCCA have an atomicAdd() operation?

// User inputs
typedef struct {
  int source_regions;
  int course_axial_intervals;
  int fine_axial_intervals;
  long segments;
  int egroups;
  int nthreads;
  int streams;
} Input;

// Source Region Structure
typedef struct {
  long fine_flux_id;
  long fine_source_id;
  long sigT_id;
} Source;

// Source Arrays
typedef struct {
  float * fine_flux_arr;
  float * fine_source_arr;
  float * sigT_arr;
} Source_Arrays;

// Table structure for computing exponential
typedef struct {
	float values[706];
	float dx;
	float maxVal;
	int N;
} Table;

occaFunction void LCG_RNG( unsigned long * state ){
  unsigned long n1;
  unsigned long a = 16807;
  unsigned long m = 2147483647;
  n1 = ( a * (*state) ) % m;
  *state = n1;
}

/* Interpolates a formed exponential table to compute ( 1- exp(-x) )
 *  at the desired x value */
occaFunction void interpolateTable(const Table * table, float x, float * out){
	// check to ensure value is in domain
	if( x > table->maxVal ){
		*out = 1.0f;
  }
	else {
		int interval    = 2 * ((int) ( x / table->dx + 0.5f * table->dx ));
		float slope     = table->values[ interval ];
		float intercept = table->values[ interval + 1 ];
		float val       = slope * x + intercept;
		*out = val;
	}
}


/* My parallelization scheme here is to basically have a single
 * block be a geometrical segment, with each thread within the
 * block represent a single energy phase. On the CPU, the
 * inner SIMD-ized loop is over energy (i.e, 100 energy groups).
 * This should allow for each BLOCK to have:
 * 		- A single state variable for the RNG
 * 		- A set of __shared__ SIMD vectors, each thread id being its idx
 */

occaKernel void run_kernel(
                           const Input              I,
                           const Source  * restrict S,
                           float         * restrict SA_fine_flux_arr,
                           float         * restrict SA_fine_source_arr,
                           float         * restrict SA_sigT_arr,
                           const Table   * restrict table,
                           unsigned long * restrict state,
                           float         * restrict state_fluxes,
                           const int                N_state_fluxes){

  for (int outerId = 0; outerId < outerDim; ++outerId; outer0){
    // int outerId = blockIdx.y * gridDim.x + blockIdx.x; // geometric segment in CUDA

    // Randomized variables (common accross all thread within block)
    shared int randIdx[3 * batchDim];

    for(int innerId = 0; innerId < innerDim; ++innerId; inner0){
      for(int randPos = innerId; randPos < batchDim; randPos += innerDim){
        // Assign RNG state
        unsigned long * localState = &state[(randPos + (batchDim * outerId)) % I.streams];

        // update state to next in sequence
        LCG_RNG(localState); randIdx[3*randPos + 0] = (*localState % N_state_fluxes);
        LCG_RNG(localState); randIdx[3*randPos + 1] = (*localState % I.source_regions);
        LCG_RNG(localState); randIdx[3*randPos + 2] = (*localState % I.fine_axial_intervals);
      }
    }

    barrier(localMemFence);

    for(int batch = 0; batch < batchDim; ++batch){
      if( (batch + (outerId * batchDim)) >= I.segments )
        continue;

      for (int innerId = 0; innerId < innerDim; ++innerId; inner0){
        const int g = innerId; // Each energy group (g) is one thread in a block

        // Thread Local (i.e., specific to E group) variables
        // Similar to SIMD vectors in CPU code
        float q0           ;
        float q1           ;
        float q2           ;
        float tau          ;
        float sigT2        ;
        float expVal       ;
        float reuse        ;
        float flux_integral;
        float tally        ;

        // Find State Flux Vector in global memory
        // (We are not concerned with coherency here as in actual
        // program threads would be organized in a more specific order)

        const int randIdx_r0 = randIdx[3*batch + 0];
        const int randIdx_r1 = randIdx[3*batch + 1];
        const int randIdx_r2 = randIdx[3*batch + 2];

        float *state_flux_ptr  = state_fluxes + randIdx_r0;
        const float state_flux = directLoad(&state_flux_ptr[g]);

        // Pick Random QSR
        const int QSR_id = randIdx_r1;

        // Pick Random Fine Axial Interval
        const int FAI_id = randIdx_r2;

        //////////////////////////////////////////////////////////
        // Attenuate Segment
        //////////////////////////////////////////////////////////

        // Some placeholder constants - In the full app some of these are
        // calculated based off position in geometry. This treatment
        // shaves off a few FLOPS, but is not significant compared to the
        // rest of the function.
        const float dz     = 0.1f;
        const float zin    = 0.3f;
        const float weight = 0.5f;
        const float mu     = 0.9f;
        const float mu2    = 0.3f;
        const float ds     = 0.7f;

        const int egroups = I.egroups;

        // load fine source region flux vector

        const long S_fine_flux_off   = S[QSR_id].fine_flux_id   + (FAI_id * egroups);
        const long S_fine_source_off = S[QSR_id].fine_source_id + (FAI_id * egroups);

        // load total cross section
        const float sigT = directLoad(&SA_sigT_arr[ S[QSR_id].sigT_id + g]);

        float * FSR_flux = &SA_fine_flux_arr[S_fine_flux_off + g];

        if( FAI_id == 0 )
          {
            float y2 = directLoad(&SA_fine_source_arr[S_fine_source_off + (0 * egroups) + g]);
            float y3 = directLoad(&SA_fine_source_arr[S_fine_source_off + (1 * egroups) + g]);

            // do linear "fitting"
            float c0 = y2;
            float c1 = (y3 - y2) / dz;

            // calculate q0, q1, q2
            q0 = c0 + c1*zin;
            q1 = c1;
            q2 = 0;
          }
        else if ( FAI_id == I.fine_axial_intervals - 1 )
          {
            // cycle over energy groups
            // load neighboring sources
            float y1 = directLoad(&SA_fine_source_arr[S_fine_source_off - (1 * egroups) + g]);
            float y2 = directLoad(&SA_fine_source_arr[S_fine_source_off + (0 * egroups) + g]);

            // do linear "fitting"
            float c0 = y2;
            float c1 = (y2 - y1) / dz;

            // calculate q0, q1, q2
            q0 = c0 + c1*zin;
            q1 = c1;
            q2 = 0;
          }
        else
          {
            // cycle over energy groups
            // load neighboring sources
            float y1 = directLoad(&SA_fine_source_arr[S_fine_source_off - (1 * egroups) + g]);
            float y2 = directLoad(&SA_fine_source_arr[S_fine_source_off + (0 * egroups) + g]);
            float y3 = directLoad(&SA_fine_source_arr[S_fine_source_off + (1 * egroups) + g]);

            // do quadratic "fitting"
            float c0 = y2;
            float c1 = (y1 - y3) / (2.f*dz);
            float c2 = (y1 - 2.f*y2 + y3) / (2.f*dz*dz);

            // calculate q0, q1, q2
            q0 = c0 + c1*zin + c2*zin*zin;
            q1 = c1 + 2.f*c2*zin;
            q2 = c2;
          }

        // calculate common values for efficiency
        tau   = sigT * ds;
        sigT2 = sigT * sigT;

        // interpolateTable( table, tau, &expVal );
        expVal = 1.f - exp( -tau );

        // Flux Integral

        // Re-used Term
        reuse = tau * (tau - 2.f) + 2.f * expVal
          / (sigT * sigT2);

        // add contribution to new source flux
        flux_integral = (q0 * tau + (sigT * state_flux - q0)
                         * expVal) / sigT2 + q1 * mu * reuse + q2 * mu2
          * (tau * (tau * (tau - 3.f) + 6.f) - 6.f * expVal)
          / (3.f * sigT2 * sigT2);

        // Prepare tally
        tally = weight * flux_integral;

        // SHOULD BE ATOMIC HERE!
        occaAtomicAdd(&FSR_flux[g], (float) tally);

        // Terms 1, 2, 3, and 4
        const float t1 = q0 * expVal / sigT;
        const float t2 = q1 * mu * (tau - expVal) / sigT2;
        const float t3 = q2 * mu2 * reuse;
        const float t4 = state_flux * (1.f - expVal);

        // Total psi
        state_flux_ptr[g] = t1 + t2 + t3 + t4;
      } // end inner0
    } // end batch
  } // end outer0
}

